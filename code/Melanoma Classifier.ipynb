{
 "metadata": {
  "kernelspec": {
   "language": "python",
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.12",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "sourceId": 10455671,
     "sourceType": "datasetVersion",
     "datasetId": 6472288
    }
   ],
   "dockerImageVersionId": 30823,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook",
   "isGpuEnabled": true
  }
 },
 "nbformat_minor": 4,
 "nbformat": 4,
 "cells": [
  {
   "cell_type": "code",
   "source": "import torch\nfrom torch import nn\n\nimport torchvision\nfrom torchvision import datasets, transforms\nfrom torchvision.transforms import ToTensor\nimport torch.nn.functional as F\n\nimport torch.optim as optim\nimport matplotlib.pyplot as plt\n\nprint(f\"PyTorch version: {torch.__version__}\\ntorchvision version: {torchvision.__version__}\")",
   "metadata": {
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2025-01-13T04:01:24.168916Z",
     "iopub.execute_input": "2025-01-13T04:01:24.169153Z",
     "iopub.status.idle": "2025-01-13T04:01:28.291657Z",
     "shell.execute_reply.started": "2025-01-13T04:01:24.169129Z",
     "shell.execute_reply": "2025-01-13T04:01:28.290616Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": "PyTorch version: 2.4.1+cu121\ntorchvision version: 0.19.1+cu121\n",
     "output_type": "stream"
    }
   ],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "source": "mean = [0.485, 0.456, 0.406]\nstd = [0.229, 0.224, 0.225]\n\n\ntransform = transforms.Compose([\n    transforms.Resize((224, 224)),     \n    transforms.RandomHorizontalFlip(),  # Randomly flip the image horizontally\n    transforms.RandomRotation(10),      # Randomly rotate the image by up to 10 degrees\n    transforms.ToTensor(), \n    transforms.Normalize(mean,std)  # Normalize to [-1, 1] range\n])",
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2025-01-13T04:01:32.953616Z",
     "iopub.execute_input": "2025-01-13T04:01:32.953963Z",
     "iopub.status.idle": "2025-01-13T04:01:32.958864Z",
     "shell.execute_reply.started": "2025-01-13T04:01:32.953938Z",
     "shell.execute_reply": "2025-01-13T04:01:32.957953Z"
    }
   },
   "outputs": [],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "source": "dataset = datasets.ImageFolder('/kaggle/input/melanoma/data/train')\nclass_names = dataset.classes\nprint(class_names)\ndataset = datasets.ImageFolder('/kaggle/input/melanoma/data/train', transform=transform)",
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2025-01-13T04:02:08.413961Z",
     "iopub.execute_input": "2025-01-13T04:02:08.414242Z",
     "iopub.status.idle": "2025-01-13T04:02:20.831269Z",
     "shell.execute_reply.started": "2025-01-13T04:02:08.414223Z",
     "shell.execute_reply": "2025-01-13T04:02:20.830601Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": "['Benign', 'Malignant']\n",
     "output_type": "stream"
    }
   ],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "source": "from torch.utils.data import random_split\n\ntotal_size = len(dataset)\nprint(f\"Total dataset size: {total_size}\")\n\ntrain_size = int(0.8 * total_size)\ntest_size = total_size - train_size\n\ntrain_data, test_data = random_split(dataset, [train_size, test_size])\nprint(f\"Number of training samples: {len(train_data)}\")\nprint(f\"Number of testing samples: {len(test_data)}\")",
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2025-01-13T04:02:34.055426Z",
     "iopub.execute_input": "2025-01-13T04:02:34.055811Z",
     "iopub.status.idle": "2025-01-13T04:02:34.083203Z",
     "shell.execute_reply.started": "2025-01-13T04:02:34.055782Z",
     "shell.execute_reply": "2025-01-13T04:02:34.082350Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": "Total dataset size: 11879\nNumber of training samples: 9503\nNumber of testing samples: 2376\n",
     "output_type": "stream"
    }
   ],
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "source": "from torch.utils.data import DataLoader\n\nBATCH_SIZE = 32\n\ntrain_dataloader = DataLoader(train_data, \n    batch_size=BATCH_SIZE, \n    shuffle=True,\n    num_workers=4\n)\n\ntest_dataloader = DataLoader(test_data,\n    batch_size=BATCH_SIZE,\n    shuffle=False,\n    num_workers=4                         \n)\n\nprint(f\"Length of train dataloader: {len(train_dataloader)} batches of {BATCH_SIZE}\")\nprint(f\"Length of test dataloader: {len(test_dataloader)} batches of {BATCH_SIZE}\")",
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2025-01-13T04:02:50.490355Z",
     "iopub.execute_input": "2025-01-13T04:02:50.490792Z",
     "iopub.status.idle": "2025-01-13T04:02:50.497524Z",
     "shell.execute_reply.started": "2025-01-13T04:02:50.490750Z",
     "shell.execute_reply": "2025-01-13T04:02:50.496656Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": "Length of train dataloader: 297 batches of 32\nLength of test dataloader: 75 batches of 32\n",
     "output_type": "stream"
    }
   ],
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "source": "image,label = dataset[0]\nimage.size()",
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2025-01-13T04:02:56.497280Z",
     "iopub.execute_input": "2025-01-13T04:02:56.497580Z",
     "iopub.status.idle": "2025-01-13T04:02:56.574378Z",
     "shell.execute_reply.started": "2025-01-13T04:02:56.497557Z",
     "shell.execute_reply": "2025-01-13T04:02:56.573468Z"
    }
   },
   "outputs": [
    {
     "execution_count": 6,
     "output_type": "execute_result",
     "data": {
      "text/plain": "torch.Size([3, 224, 224])"
     },
     "metadata": {}
    }
   ],
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "source": "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\ndevice\n\nfrom torchvision import models\n\nclass ResNet(nn.Module):\n    def __init__(self, num_classes=2, pretrained=True):\n        super(ResNet, self).__init__()\n        # Load pre-trained ResNet50\n        self.model = models.resnet50(pretrained=pretrained)\n        num_ftrs = self.model.fc.in_features\n        self.model.fc = nn.Linear(num_ftrs, num_classes)\n\n        # Freeze all layers except the final FC layer\n        for param in self.model.parameters():\n            param.requires_grad = False\n\n        for param in self.model.fc.parameters():\n            param.requires_grad = True\n\n    def forward(self, x):\n        return self.model(x)",
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2025-01-13T04:05:58.098606Z",
     "iopub.execute_input": "2025-01-13T04:05:58.098939Z",
     "iopub.status.idle": "2025-01-13T04:05:58.104454Z",
     "shell.execute_reply.started": "2025-01-13T04:05:58.098915Z",
     "shell.execute_reply": "2025-01-13T04:05:58.103598Z"
    }
   },
   "outputs": [],
   "execution_count": 12
  },
  {
   "cell_type": "code",
   "source": "net = ResNet()\nnet.to(device)\nnet",
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2025-01-13T04:06:00.110945Z",
     "iopub.execute_input": "2025-01-13T04:06:00.111256Z",
     "iopub.status.idle": "2025-01-13T04:06:01.344044Z",
     "shell.execute_reply.started": "2025-01-13T04:06:00.111232Z",
     "shell.execute_reply": "2025-01-13T04:06:01.343140Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "text": "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n  warnings.warn(msg)\nDownloading: \"https://download.pytorch.org/models/resnet50-0676ba61.pth\" to /root/.cache/torch/hub/checkpoints/resnet50-0676ba61.pth\n100%|██████████| 97.8M/97.8M [00:00<00:00, 223MB/s]\n",
     "output_type": "stream"
    },
    {
     "execution_count": 13,
     "output_type": "execute_result",
     "data": {
      "text/plain": "ResNet(\n  (model): ResNet(\n    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (relu): ReLU(inplace=True)\n    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n    (layer1): Sequential(\n      (0): Bottleneck(\n        (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n        (downsample): Sequential(\n          (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n      )\n      (1): Bottleneck(\n        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n      )\n      (2): Bottleneck(\n        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n      )\n    )\n    (layer2): Sequential(\n      (0): Bottleneck(\n        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n        (downsample): Sequential(\n          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n      )\n      (1): Bottleneck(\n        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n      )\n      (2): Bottleneck(\n        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n      )\n      (3): Bottleneck(\n        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n      )\n    )\n    (layer3): Sequential(\n      (0): Bottleneck(\n        (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n        (downsample): Sequential(\n          (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n          (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n      )\n      (1): Bottleneck(\n        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n      )\n      (2): Bottleneck(\n        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n      )\n      (3): Bottleneck(\n        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n      )\n      (4): Bottleneck(\n        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n      )\n      (5): Bottleneck(\n        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n      )\n    )\n    (layer4): Sequential(\n      (0): Bottleneck(\n        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n        (downsample): Sequential(\n          (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n          (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n      )\n      (1): Bottleneck(\n        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n      )\n      (2): Bottleneck(\n        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n      )\n    )\n    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n    (fc): Linear(in_features=2048, out_features=2, bias=True)\n  )\n)"
     },
     "metadata": {}
    }
   ],
   "execution_count": 13
  },
  {
   "cell_type": "code",
   "source": "loss_function = nn.CrossEntropyLoss()\noptimizer = torch.optim.Adam(net.parameters(), lr=0.001, weight_decay=1e-5)",
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2025-01-13T04:06:52.727795Z",
     "iopub.execute_input": "2025-01-13T04:06:52.728108Z",
     "iopub.status.idle": "2025-01-13T04:06:52.732745Z",
     "shell.execute_reply.started": "2025-01-13T04:06:52.728083Z",
     "shell.execute_reply": "2025-01-13T04:06:52.731987Z"
    }
   },
   "outputs": [],
   "execution_count": 15
  },
  {
   "cell_type": "code",
   "source": [
    "from torch.optim.lr_scheduler import StepLR\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "num_epochs = 30\n",
    "best_val_accuracy = 0.0\n",
    "\n",
    "# Learning rate scheduler (optional)\n",
    "scheduler = StepLR(optimizer, step_size=7, gamma=0.1)  # Reduce LR by factor of 0.1 every 7 epochs\n",
    "\n",
    "# Lists to store loss and accuracy for each epoch\n",
    "train_loss_list = []\n",
    "train_acc_list = []\n",
    "val_loss_list = []\n",
    "val_acc_list = []\n",
    "\n",
    "# Lists to store true labels and predictions for performance metrics\n",
    "all_labels = []\n",
    "all_preds = []\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    # Set model to training mode\n",
    "    net.train()\n",
    "    \n",
    "    running_loss = 0.0\n",
    "    correct_train = 0\n",
    "    total_train = 0\n",
    "\n",
    "    # Training loop\n",
    "    for inputs, labels in train_dataloader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        # Zero gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = net(inputs)\n",
    "        loss = loss_function(outputs, labels)\n",
    "        \n",
    "        # Backward pass and optimization\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Track training loss\n",
    "        running_loss += loss.item()\n",
    "        \n",
    "        # Track accuracy\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        total_train += labels.size(0)\n",
    "        correct_train += (predicted == labels).sum().item()\n",
    "    \n",
    "    train_accuracy = 100 * correct_train / total_train\n",
    "    train_loss = running_loss / len(train_dataloader)\n",
    "\n",
    "    train_loss_list.append(train_loss)\n",
    "    train_acc_list.append(train_accuracy)\n",
    "\n",
    "    # Validation loop\n",
    "    net.eval()\n",
    "    correct_val = 0\n",
    "    total_val = 0\n",
    "    running_val_loss = 0.0\n",
    "\n",
    "    # Clear previous epoch's labels and predictions\n",
    "    all_labels = []\n",
    "    all_preds = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in test_dataloader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "            outputs = net(inputs)\n",
    "            loss = loss_function(outputs, labels)\n",
    "\n",
    "            running_val_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total_val += labels.size(0)\n",
    "            correct_val += (predicted == labels).sum().item()\n",
    "\n",
    "            # Collect labels and predictions\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "            all_preds.extend(predicted.cpu().numpy())\n",
    "\n",
    "    val_accuracy = 100 * correct_val / total_val\n",
    "    val_loss = running_val_loss / len(test_dataloader)\n",
    "\n",
    "    val_loss_list.append(val_loss)\n",
    "    val_acc_list.append(val_accuracy)\n",
    "\n",
    "    # Step learning rate scheduler\n",
    "    scheduler.step()\n",
    "\n",
    "    # Print training and validation results per epoch\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}] - Train Loss: {train_loss:.4f}, Train Acc: {train_accuracy:.2f}% | Val Loss: {val_loss:.4f}, Val Acc: {val_accuracy:.2f}%\")\n",
    "\n",
    "    # Save the best model based on validation accuracy\n",
    "    if val_accuracy > best_val_accuracy:\n",
    "        best_val_accuracy = val_accuracy\n",
    "        torch.save(net.state_dict(), '../app/best_model.pth')\n",
    "        print(f\"Saved best model with accuracy: {best_val_accuracy:.2f}%\")\n",
    "\n",
    "# After training, compute and print classification report  # Replace with your actual class names\n",
    "\n",
    "print(\"\\nMetrics per class::\")\n",
    "print(classification_report(all_labels, all_preds, target_names=class_names))\n",
    "\n",
    "# Plot Loss\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.plot(range(1, num_epochs+1), train_loss_list, label='Training Loss')\n",
    "plt.plot(range(1, num_epochs+1), val_loss_list, label='Validation Loss')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Plot Accuracy\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.plot(range(1, num_epochs+1), train_acc_list, label='Training Accuracy')\n",
    "plt.plot(range(1, num_epochs+1), val_acc_list, label='Validation Accuracy')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy (%)')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ],
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2025-01-13T04:06:53.855302Z",
     "iopub.execute_input": "2025-01-13T04:06:53.855614Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": "Epoch [1/30] - Train Loss: 0.3906, Train Acc: 82.28% | Val Loss: 0.3066, Val Acc: 86.24%\nSaved best model with accuracy: 86.24%\nEpoch [2/30] - Train Loss: 0.3563, Train Acc: 84.37% | Val Loss: 0.3074, Val Acc: 86.57%\nSaved best model with accuracy: 86.57%\nEpoch [3/30] - Train Loss: 0.3317, Train Acc: 85.37% | Val Loss: 0.3218, Val Acc: 85.40%\nEpoch [4/30] - Train Loss: 0.3316, Train Acc: 85.92% | Val Loss: 0.2936, Val Acc: 86.95%\nSaved best model with accuracy: 86.95%\nEpoch [5/30] - Train Loss: 0.3248, Train Acc: 86.04% | Val Loss: 0.2971, Val Acc: 87.12%\nSaved best model with accuracy: 87.12%\nEpoch [6/30] - Train Loss: 0.3156, Train Acc: 86.50% | Val Loss: 0.3275, Val Acc: 85.86%\nEpoch [7/30] - Train Loss: 0.3182, Train Acc: 86.50% | Val Loss: 0.3697, Val Acc: 83.25%\nEpoch [8/30] - Train Loss: 0.2909, Train Acc: 87.39% | Val Loss: 0.2772, Val Acc: 87.67%\nSaved best model with accuracy: 87.67%\nEpoch [9/30] - Train Loss: 0.2817, Train Acc: 87.49% | Val Loss: 0.2803, Val Acc: 88.17%\nSaved best model with accuracy: 88.17%\nEpoch [10/30] - Train Loss: 0.2860, Train Acc: 87.53% | Val Loss: 0.2786, Val Acc: 87.25%\nEpoch [11/30] - Train Loss: 0.2811, Train Acc: 88.08% | Val Loss: 0.2788, Val Acc: 87.67%\nEpoch [12/30] - Train Loss: 0.2913, Train Acc: 87.55% | Val Loss: 0.2917, Val Acc: 87.67%\nEpoch [13/30] - Train Loss: 0.2845, Train Acc: 87.73% | Val Loss: 0.2858, Val Acc: 87.33%\nEpoch [14/30] - Train Loss: 0.2883, Train Acc: 87.35% | Val Loss: 0.2798, Val Acc: 87.29%\nEpoch [15/30] - Train Loss: 0.2826, Train Acc: 87.96% | Val Loss: 0.2911, Val Acc: 87.67%\nEpoch [16/30] - Train Loss: 0.2888, Train Acc: 87.80% | Val Loss: 0.2795, Val Acc: 87.84%\nEpoch [17/30] - Train Loss: 0.2864, Train Acc: 87.81% | Val Loss: 0.2787, Val Acc: 87.46%\nEpoch [18/30] - Train Loss: 0.2807, Train Acc: 88.09% | Val Loss: 0.2758, Val Acc: 87.79%\nEpoch [19/30] - Train Loss: 0.2813, Train Acc: 88.05% | Val Loss: 0.2755, Val Acc: 88.13%\nEpoch [20/30] - Train Loss: 0.2866, Train Acc: 87.71% | Val Loss: 0.2818, Val Acc: 87.75%\nEpoch [21/30] - Train Loss: 0.2783, Train Acc: 88.18% | Val Loss: 0.2740, Val Acc: 88.47%\nSaved best model with accuracy: 88.47%\nEpoch [22/30] - Train Loss: 0.2842, Train Acc: 87.60% | Val Loss: 0.2781, Val Acc: 87.50%\nEpoch [23/30] - Train Loss: 0.2893, Train Acc: 87.38% | Val Loss: 0.2782, Val Acc: 88.26%\nEpoch [24/30] - Train Loss: 0.2796, Train Acc: 88.09% | Val Loss: 0.2753, Val Acc: 87.92%\nEpoch [25/30] - Train Loss: 0.2832, Train Acc: 87.66% | Val Loss: 0.2729, Val Acc: 87.71%\nEpoch [26/30] - Train Loss: 0.2843, Train Acc: 87.66% | Val Loss: 0.2742, Val Acc: 88.22%\n",
     "output_type": "stream"
    }
   ],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": "",
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "execution_count": null
  }
 ]
}
